###################################################################################################
### Description: 
# This function takes in the results of findhits function and calculates the seekr pearson correlation r and p value between the hit sequences and the query sequence

### Details:
# this function takes in the output of findhits function and the query sequence fasta file with a background fasta file
# it fit the background sequences to the common10 distributions and takes the best ranked distribution
# it calculates the seekr pearson correlation r and p values between the hit sequences and the query sequence based on the best ranked distribution
# it adds the seekr r and p value to the hits dataframe
# on top of the existing kmer log likelihood score (kmerLLR)
# the seekr r and p value could provide additional information about the similarity between the hit sequences and the query sequence


### Input:
# hitsdir: Path to the directory of the .txt file generated by findhits function
# queryfadir: Path to the fasta file of query seq (e.g. functional regions of a ncRNA)
# if query fasta contains more than one sequence 
# all the sequences in query fasta file will be merged to one sequence for calculating seekr.pearson 
# bkgfadir: fasta file directory for background sequences, which serves as the normalizing factor for the input of seekr_norm_vectors and used by seekr_kmer_counts function
# knum: a single integer value for kmer number, must be the same as the kmer number used in the findhits function
# lenmin: keep hits sequences that have length > lenmin for calculating stats in the output, default=100. if no filter is needed, set to 0
# lenmax: keep hits sequences that have length < lenmax for calculating stats in the output, default=1000. if no filter is needed, set to a super large number
# pfilter: only keep hits sequences that have seekr pearson correlation p value < pfilter for calculating stats in the output, default=1.1. if no filter is needed, set to 1.1
# rfilter: only keep hits sequences that have seekr pearson correlation r value > rfilter for calculating stats in the output, default=-1.1. if no filter is needed, set to -1.1
# outputdir: path of output directory, default is current directory, save the final dataframe together with other intermediate files
# progressbar: whether to show progress bar, default=True: show progress bar

### Output:
# a dataframe with seekr r and p value added to the findhits dataframe
# outputname is automatically generated as the input findhits filename with '_seekr' appended to it

### Example:
# from hmseekr.hitseekr import hitseekr

# addpvals = hitseekr(hitsdir='/Users/shuang/mSEEKR/mm10expmap_queryA_4_viterbi.txt',
#                     queryfadir='/Users/shuang/mSEEKR/fastaFiles/mXist_rA.fa', 
#                     bkgfadir='/Users/shuang/mSEEKR/fastaFiles/vM25.lncRNA.can.500.nodup.fa',
#                     knum=4, lenmin=50, lenmax=1000, pfilter=0.05, rfilter=0, outputdir='./', progressbar=True)


########################################################################################################

from seekr.kmer_counts import BasicCounter as seekrBasicCounter 
from seekr.fasta_reader import Reader as seekrReader
from seekr.pearson import pearson as seekrPearson
from seekr.find_pval import find_pval
from seekr.find_dist import find_dist

import os
import numpy as np
import pandas as pd


def hitseekr(hitsdir, queryfadir, bkgfadir, knum, lenmin=100, lenmax=1000, pfilter=1.1, rfilter=-1.1, outputdir='./', progressbar=True):

    # check outputdir format
    if not outputdir.endswith('/'):
        outputdir+='/'

    # strip the hitsdir to get the hits filename
    hitsname = hitsdir.split('/')[-1]
    # remove the .txt extension
    hitsname = hitsname.split('.')[0]

    if not os.path.exists(f'{outputdir}intermediates_{hitsname}/'):
        os.mkdir(f'{outputdir}intermediates_{hitsname}/')

    # read the hits file
    hits = pd.read_csv(hitsdir, sep='\t')

    # only keep the rows in hits if Length col is greater than lengthfilter
    hits = hits[hits['Length']>lenmin]
    hits = hits[hits['Length']<lenmax]

    # check if there are any hits left after filtering
    # if not, return an empty dataframe and print warning
    if hits.shape[0] == 0:
        print('No hits left after length filtering')
        print('Please adjust the length filter lenmin and lenmax')
        print('No file is saved')
        return pd.DataFrame()

    # save the hits sequences
    hits_seq = hits['Sequence']
    hits_header = hits['seqName']+'_'+hits['Start'].astype(str)+'_'+hits['End'].astype(str)
    hitseqdir = f'{outputdir}intermediates_{hitsname}/hits_seqs.fa'
    
    # save the hits sequences and its header to a fasta file
    with open(hitseqdir, 'w') as f:
        for i in range(len(hits_seq)):
            f.write(f'{hits_header.iloc[i]}\n{hits_seq.iloc[i]}\n')

    # load in the background sequences and calculate the seekr norm vectors
    print('Calculating background norm vectors')
    print('This could take a while if the background fasta file is large')
    bkg_norm = seekrBasicCounter(bkgfadir, k=knum, log2='Log2.post', silent=True) 
    bkg_norm.get_counts() 

    mean_path = f'{outputdir}intermediates_{hitsname}/bkg_mean_{knum}mers.npy' 
    std_path = f'{outputdir}intermediates_{hitsname}/bkg_std_{knum}mers.npy' 
    np.save(mean_path, bkg_norm.mean)
    np.save(std_path, bkg_norm.std)
    print('Background norm vectors saved')


    # merge the query fasta sequences if there are more than one sequence
    qseqs = seekrReader(queryfadir).get_seqs()
    
    if len(qseqs) > 1:
        print('More than one sequence in query fasta file')
        print('All the query sequences will be merged for calculating seekr.pearson')
        print('Merged fasta file is saved under seqs folder as seekrquery.fa')
        seekrqueryfadir = f'{outputdir}intermediates_{hitsname}/seekrquery.fa'
        qseqs = '$'.join(qseqs)
        qseqfile = open(seekrqueryfadir, 'w')
        qseqfile.write('>concatenatedQuery' + '\n' + qseqs + '\n')
        qseqfile.close()

    else:
        seekrqueryfadir = queryfadir

    # calculate r value
    query_count = seekrBasicCounter(infasta=queryfadir, outfile=f'{outputdir}intermediates_{hitsname}/seekrquery_counts.csv', k=knum, mean=mean_path, std=std_path, log2='Log2.post', silent=True) 
    query_count.make_count_file()

    hits_count = seekrBasicCounter(infasta=hitseqdir, outfile=f'{outputdir}intermediates_{hitsname}/seekrhits_counts.csv', k=knum, mean=mean_path, std=std_path, log2='Log2.post', silent=True) 
    hits_count. make_count_file() 

    sim = seekrPearson(hits_count.counts,query_count.counts)
    hits['seekr_rval']=sim
    

    # find the dist of background
    fitres = find_dist(inputseq=bkgfadir, k_mer=knum, models='common10', 
                       subsetting=True, subset_size = 10000, 
                       fit_model=True, statsmethod='ks',progress_bar=progressbar, 
                       outputname=f'{outputdir}intermediates_{hitsname}/fitres')

    # fitres = find_dist(inputseq=bkgfadir, k_mer=knum, models='common10', 
    #                    subsetting=True, subset_size = 10000, 
    #                    fit_model=True, statsmethod='ks',progress_bar=progressbar, 
    #                    plotfit=f'{outputdir}intermediates_{hitsname}/modelfitplot', outputname=f'{outputdir}intermediates_{hitsname}/fitres')
    
    # delete the intermediate files generated by find_dist
    #os.remove(f'bkg_mean_{knum}mers.npy')
    #os.remove(f'bkg_std_{knum}mers.npy')
    
    # find the p value of the seekr r score
    pvals=find_pval(seq1file=hitseqdir, seq2file=seekrqueryfadir, 
                    mean_path=mean_path, std_path=std_path,
                    k_mer=knum, fitres=fitres, log2='Log2.post', 
                    bestfit=1, outputname=f'{outputdir}intermediates_{hitsname}/hits_seekr_pval', progress_bar=progressbar)
    
    # change the first column name of pvals
    pvals.columns = ['seekr_pval']
    pvals = pvals.reset_index(drop=True)
    hits = hits.reset_index(drop=True)

    # add the pvals seekr_pval values to the hits dataframe as a new column seekr_pval
    hits['seekr_pval'] = pvals['seekr_pval']

    # filter the hits dataframe based on the seekr p value
    hits = hits[hits['seekr_pval']<pfilter]

    # check if there are any hits left after filtering
    # if not, return an empty dataframe and print warning
    if hits.shape[0] == 0:
        print('No hits left after seekr p value filtering')
        print('Please adjust the seekr p value filter pfilter')
        print('No file is saved')
        #return pd.DataFrame()
    else:
        hits = hits[hits['seekr_rval']>rfilter]

        if hits.shape[0] == 0:
            print('No hits left after seekr r value filtering')
            print('Please adjust the seekr r value filter rfilter')
            print('No file is saved')
            #return pd.DataFrame()
        else: 
            # save the final hits dataframe
            hits.to_csv(f'{outputdir}{hitsname}_seekr.txt',sep='\t', index=False)
            #return hits


        


    

        


